"q1_position_in_trust" = 2,
"q2_rsc_office_met" = 3,
"q12_main_challenges" = 4,
"q15_not_expectations" = 5,
"q22_changes" = 6,
"q24_reflections" = 7)
# Focussing on Q24: Do you have any other reflections about your meetings with your RSC office?
# Take a look at some of the data for comparisons later
sample <- 27:37
new_data[sample,"q24_reflections"]
rm(list=ls())
# setup --------------------------------------------------------------------------------------------------------
# Load dplyr to assist
library(dplyr)
# Import raw data
data <- readxl::read_xlsx("../demo_data.xlsx")
# Show questions
names(data)
# Transform into clean format
new_data <- data %>%
rename("user" = 1,
"q1_position_in_trust" = 2,
"q2_rsc_office_met" = 3,
"q12_main_challenges" = 4,
"q15_not_expectations" = 5,
"q22_changes" = 6,
"q24_reflections" = 7)
# Focussing on Q24: Do you have any other reflections about your meetings with your RSC office?
# Take a look at some of the data for comparisons later
sample <- 27:37
new_data[sample,"q24_reflections"]
# anonymise() ---------------------------------------------------------------------------------------
# See names 'Joe Bloggs' and 'John Doe' - column needs to be anonymised
# Default behaviour
anon_data <- new_data %>%
anonymise(q24_reflections)
anon_data[sample,"q24_reflections"]
# If we want to distinguish between the different people (i.e. for analysis, see if one person mentioned alot etc.)
anon_data <- new_data %>%
anonymise(q24_reflections,
identify = TRUE)
anon_data[sample,"q24_reflections"] # Random numbers assigned
# If we want to make the column gender neutral as well
anon_data <- new_data %>%
anonymise(q24_reflections,
identify = TRUE,
gender = TRUE)
anon_data[sample,"q24_reflections"]
# If we want to anonymise certain names (i.e. we have a list of certain names)
names_to_anonymise <- c("Joe Bloggs", "the RSC")
anon_data <- new_data %>%
anonymise(q24_reflections,
auto = FALSE, # So that the function doesn't automatically overwrite every name it finds
add_names = names_to_anonymise, # Manually defined names to anonymise
identify = TRUE,
gender = TRUE)
anon_data[sample,"q24_reflections"]
# Default behaviour for rest of the demo
anon_data <- new_data %>%
anonymise(q24_reflections)
anon_data[sample,"q24_reflections"]
# clean_column() -----------------------------------------------------------------------------------------
# After anonymising, column needs to be standardised (lower case, punctuation etc.) before it can be analysed
clean_data <- anon_data %>%
clean_column(q24_reflections)
clean_data[sample,"q24_reflections"]
# If we want to keep 'null responses'
clean_data <- anon_data %>%
clean_column(q24_reflections,
null_response = FALSE)
clean_data[sample,"q24_reflections"]
# common_words() --------------------------------------------------------------------------------------------
# Simple frequency analysis, filters out words that appear less than 5 times so
# filters out groups with only a couple of respondents
clean_data %>%
common_words(q24_reflections)
# More words
clean_data %>%
common_words(q24_reflections,
n = 10)
# Remove certain words
clean_data %>%
common_words(q24_reflections,
remove = c("meeting", "rsc", "trust"),
n = 10)
# Breakdown by demographic
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1)
# To include all groups
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 5) # Top 5 words but some are being excluded because they occur less than 5 times
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 5,
min = 0) # include top five words regardless of how often they occur
# Stopwords are currently being removed, to keep them in
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
stopwords = FALSE)
# Can also calculate the proportion of responses in each group
# that mentioned the word
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1,
proportion = TRUE)
# Finally, if exporting to external document, can make it more visually appealing with prettify()
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
proportion = TRUE,
remove = c("meeting", "rsc", "trust"),
n = 2) %>%
prettify(alias = c("Which RSC did the respondent meet?" = "q2_rsc_office_met"),
count_bar = TRUE,
colour_groups = TRUE)
# n_grams() --------------------------------------------------------------------------------------------------
# Method of tabulating most common n-grams, removing n_grams that are mostly stopwords
clean_data %>%
n_grams(q24_reflections) # defaults to bigrams
# Can decrease the threshold to be stricter on stopwords
clean_data %>%
n_grams(q24_reflections,
stop_thresh = 0) # 0 means exclude n-grams that contain one or more stopwords, 1 means include all n-grams
# Other options
clean_data %>%
n_grams(q24_reflections,
n = 3, # trigrams
word = "meeting", # filter to only include n-grams containing the word 'meeting'
stop_thresh = 0.4) # allow only one stopword per trigram
# Prettify
clean_data %>%
n_grams(q24_reflections,
n = 3, # trigrams
word = "meeting", # filter to only include n-grams containing the word 'better'
stop_thresh = 0.4) %>% # allow only one stopword per ngram
prettify(alias = c("Phrase" = "ngram"),
count_bar = TRUE)
# Example workflow ---------------------------------------------------------------------------------------------
# (After running setup)
new_data %>%
anonymise(q24_reflections,
identify = TRUE) %>%
clean_column(q24_reflections) %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1) %>%
prettify(alias = c("Which RSC did the respondent meet?" = "q2_rsc_office_met"),
count_bar = TRUE)
devtools::load_all(".")
# setup --------------------------------------------------------------------------------------------------------
# Load dplyr to assist
library(dplyr)
# Import raw data
data <- readxl::read_xlsx("../demo_data.xlsx")
# Show questions
names(data)
# Transform into clean format
new_data <- data %>%
rename("user" = 1,
"q1_position_in_trust" = 2,
"q2_rsc_office_met" = 3,
"q12_main_challenges" = 4,
"q15_not_expectations" = 5,
"q22_changes" = 6,
"q24_reflections" = 7)
# Focussing on Q24: Do you have any other reflections about your meetings with your RSC office?
# Take a look at some of the data for comparisons later
sample <- 27:37
new_data[sample,"q24_reflections"]
# anonymise() ---------------------------------------------------------------------------------------
# See names 'Joe Bloggs' and 'John Doe' - column needs to be anonymised
# Default behaviour
anon_data <- new_data %>%
anonymise(q24_reflections)
anon_data[sample,"q24_reflections"]
# If we want to distinguish between the different people (i.e. for analysis, see if one person mentioned alot etc.)
anon_data <- new_data %>%
anonymise(q24_reflections,
identify = TRUE)
anon_data[sample,"q24_reflections"] # Random numbers assigned
# If we want to make the column gender neutral as well
anon_data <- new_data %>%
anonymise(q24_reflections,
identify = TRUE,
gender = TRUE)
anon_data[sample,"q24_reflections"]
# If we want to anonymise certain names (i.e. we have a list of certain names)
names_to_anonymise <- c("Joe Bloggs", "the RSC")
anon_data <- new_data %>%
anonymise(q24_reflections,
auto = FALSE, # So that the function doesn't automatically overwrite every name it finds
add_names = names_to_anonymise, # Manually defined names to anonymise
identify = TRUE,
gender = TRUE)
anon_data[sample,"q24_reflections"]
# Default behaviour for rest of the demo
anon_data <- new_data %>%
anonymise(q24_reflections)
anon_data[sample,"q24_reflections"]
# clean_column() -----------------------------------------------------------------------------------------
# After anonymising, column needs to be standardised (lower case, punctuation etc.) before it can be analysed
clean_data <- anon_data %>%
clean_column(q24_reflections)
clean_data[sample,"q24_reflections"]
# If we want to keep 'null responses'
clean_data <- anon_data %>%
clean_column(q24_reflections,
null_response = FALSE)
clean_data[sample,"q24_reflections"]
# common_words() --------------------------------------------------------------------------------------------
# Simple frequency analysis, filters out words that appear less than 5 times so
# filters out groups with only a couple of respondents
clean_data %>%
common_words(q24_reflections)
# More words
clean_data %>%
common_words(q24_reflections,
n = 10)
# Remove certain words
clean_data %>%
common_words(q24_reflections,
remove = c("meeting", "rsc", "trust"),
n = 10)
# Breakdown by demographic
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1)
# To include all groups
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 5) # Top 5 words but some are being excluded because they occur less than 5 times
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 5,
min = 0) # include top five words regardless of how often they occur
# Stopwords are currently being removed, to keep them in
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
stopwords = FALSE)
# Can also calculate the proportion of responses in each group
# that mentioned the word
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1,
proportion = TRUE)
# Finally, if exporting to external document, can make it more visually appealing with prettify()
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
proportion = TRUE,
remove = c("meeting", "rsc", "trust"),
n = 2) %>%
prettify(alias = c("Which RSC did the respondent meet?" = "q2_rsc_office_met"),
count_bar = TRUE,
colour_groups = TRUE)
# n_grams() --------------------------------------------------------------------------------------------------
# Method of tabulating most common n-grams, removing n_grams that are mostly stopwords
clean_data %>%
n_grams(q24_reflections) # defaults to bigrams
# Can decrease the threshold to be stricter on stopwords
clean_data %>%
n_grams(q24_reflections,
stop_thresh = 0) # 0 means exclude n-grams that contain one or more stopwords, 1 means include all n-grams
# Other options
clean_data %>%
n_grams(q24_reflections,
n = 3, # trigrams
word = "meeting", # filter to only include n-grams containing the word 'meeting'
stop_thresh = 0.4) # allow only one stopword per trigram
# Prettify
clean_data %>%
n_grams(q24_reflections,
n = 3, # trigrams
word = "meeting", # filter to only include n-grams containing the word 'better'
stop_thresh = 0.4) %>% # allow only one stopword per ngram
prettify(alias = c("Phrase" = "ngram"),
count_bar = TRUE)
# Example workflow ---------------------------------------------------------------------------------------------
# (After running setup)
new_data %>%
anonymise(q24_reflections,
identify = TRUE) %>%
clean_column(q24_reflections) %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1) %>%
prettify(alias = c("Which RSC did the respondent meet?" = "q2_rsc_office_met"),
count_bar = TRUE)
rm(list=ls())
# Load dplyr to assist
library(dplyr)
# Import raw data
data <- readxl::read_xlsx("../demo_data.xlsx")
# Show questions
names(data)
# Load surveyr package
devtools::load_all()
# Transform into clean format
new_data <- data %>%
rename("user" = 1,
"q1_position_in_trust" = 2,
"q2_rsc_office_met" = 3,
"q12_main_challenges" = 4,
"q15_not_expectations" = 5,
"q22_changes" = 6,
"q24_reflections" = 7)
# Focussing on Q24: Do you have any other reflections about your meetings with your RSC office?
# Take a look at some of the data for comparisons later
sample <- 27:37
new_data[sample,"q24_reflections"]
rm(list=ls())
# Load dplyr to assist
library(dplyr)
# Load surveyr package
devtools::load_all()
# Import raw data
data <- readxl::read_xlsx("../demo_data.xlsx")
# Show questions
names(data)
# Transform into clean format
new_data <- data %>%
rename("user" = 1,
"q1_position_in_trust" = 2,
"q2_rsc_office_met" = 3,
"q12_main_challenges" = 4,
"q15_not_expectations" = 5,
"q22_changes" = 6,
"q24_reflections" = 7)
# Focussing on Q24: Do you have any other reflections about your meetings with your RSC office?
# Take a look at some of the data for comparisons later
sample <- 27:37
new_data[sample,"q24_reflections"]
# See names 'Joe Bloggs' and 'John Doe' - column needs to be anonymised
# Default behaviour
anon_data <- new_data %>%
anonymise(q24_reflections)
anon_data[sample,"q24_reflections"]
# If we want to distinguish between the different people (i.e. for analysis, see if one person mentioned alot etc.)
anon_data <- new_data %>%
anonymise(q24_reflections,
identify = TRUE)
anon_data[sample,"q24_reflections"] # Random numbers assigned
# If we want to make the column gender neutral as well
anon_data <- new_data %>%
anonymise(q24_reflections,
identify = TRUE,
gender = TRUE)
anon_data[sample,"q24_reflections"]
# If we want to anonymise certain names (i.e. we have a list of certain names)
names_to_anonymise <- c("Joe Bloggs", "the RSC")
anon_data <- new_data %>%
anonymise(q24_reflections,
auto = FALSE, # So that the function doesn't automatically overwrite every name it finds
add_names = names_to_anonymise, # Manually defined names to anonymise
identify = TRUE,
gender = TRUE)
anon_data[sample,"q24_reflections"]
# Default behaviour for rest of the demo
anon_data <- new_data %>%
anonymise(q24_reflections)
# clean_column() -----------------------------------------------------------------------------------------
# After anonymising, column needs to be standardised (lower case, punctuation etc.) before it can be analysed
clean_data <- anon_data %>%
clean_column(q24_reflections)
clean_data[sample,"q24_reflections"]
# If we want to keep 'null responses'
clean_data <- anon_data %>%
clean_column(q24_reflections,
null_response = FALSE)
clean_data[sample,"q24_reflections"]
# common_words() --------------------------------------------------------------------------------------------
# Simple frequency analysis, filters out words that appear less than 5 times so
# filters out groups with only a couple of respondents
clean_data %>%
common_words(q24_reflections)
# More words
clean_data %>%
common_words(q24_reflections,
n = 10)
# Remove certain words
clean_data %>%
common_words(q24_reflections,
remove = c("meeting", "rsc", "trust"),
n = 10)
# Breakdown by demographic
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1)
# To include all groups
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 5) # Top 5 words but some are being excluded because they occur less than 5 times
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 5,
min = 0) # include top five words regardless of how often they occur
# Stopwords are currently being removed, to keep them in
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
stopwords = FALSE)
# Can also calculate the proportion of responses in each group
# that mentioned the word
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1,
proportion = TRUE)
# Finally, if exporting to external document, can make it more visually appealing with prettify()
clean_data %>%
common_words(q24_reflections,
q2_rsc_office_met,
proportion = TRUE,
remove = c("meeting", "rsc", "trust"),
n = 2) %>%
prettify(alias = c("Which RSC did the respondent meet?" = "q2_rsc_office_met"),
count_bar = TRUE,
colour_groups = TRUE)
# n_grams() --------------------------------------------------------------------------------------------------
# Method of tabulating most common n-grams, removing n_grams that are mostly stopwords
clean_data %>%
n_grams(q24_reflections) # defaults to bigrams
# Can decrease the threshold to be stricter on stopwords
clean_data %>%
n_grams(q24_reflections,
stop_thresh = 0) # 0 means exclude n-grams that contain one or more stopwords, 1 means include all n-grams
# Other options
clean_data %>%
n_grams(q24_reflections,
n = 3, # trigrams
word = "meeting", # filter to only include n-grams containing the word 'meeting'
stop_thresh = 0.4) # allow only one stopword per trigram
# Prettify
clean_data %>%
n_grams(q24_reflections,
n = 3, # trigrams
word = "meeting", # filter to only include n-grams containing the word 'better'
stop_thresh = 0.4) %>% # allow only one stopword per ngram
prettify(alias = c("Phrase" = "ngram"),
count_bar = TRUE)
# Example workflow ---------------------------------------------------------------------------------------------
# (After running setup)
new_data %>%
anonymise(q24_reflections,
identify = TRUE) %>%
clean_column(q24_reflections) %>%
common_words(q24_reflections,
q2_rsc_office_met,
remove = c("meeting", "rsc", "trust"),
n = 1) %>%
prettify(alias = c("Which RSC did the respondent meet?" = "q2_rsc_office_met"),
count_bar = TRUE)
library(sentimentr)
install.packages('sentimentr')
install.packages('sentimentr')
sentimentr::emotion("This sentence is a sample sentence")
sentimentr::emotion("We had a good time, everyone was very helpful.")
sentimentr::emotion("We did not have a good time, everyone was very helpful.")
sentimentr::emotion("We did not have a good time, nobody was very helpful.")
sentimentr::emotion("We did not have a good time, nobody was very helpful.", drop.unused.emotions=TRUE)
sentimentr::profanity("This is a polite sample sentence for looking at profanity.")
sentimentr::profanity(text.var = "This is a polite sample sentence for looking at profanity.")
?sentimentr::profanity
sentimentr::profanity(text.var = "This is a polite sample sentence for looking at profanity.")
sentimentr::profanity(rep(text.var = "This is a polite sample sentence for looking at profanity."))
sentimentr::profanity(text.var = "This is a polite sample sentence for looking at profanity.",
profanity_list = unique(tolower(lexicon::profanity_alvarez)))
?textclean::replace_grade()
textclean::replace_grade("I got an A+")
textclean::replace_grade("I got an D")
textclean::replace_grade("I got a D")
textclean::replace_names("Hello said Chris to James")
textclean::replace_names("Hello said Chris Matthews to James")
textclean::replace_names("Hello said Chris Matthews-Clarkson to James")
textclean::replace_names("Hello said Chris Matthews-Clarkson to James on the Jetty of the Harbour")
textclean::replace_names("Hello said Chris Matthews-Clarkson to James on the Jetty of the Harbour.")
textclean::replace_rating("It was 5/10")
textclean::replace_rating("It was 9/10")
textclean::replace_rating("It was 10/10")
sentimentr::sentiment("This is a sample sentence")
sentimentr::sentiment("This is an excellentsample sentence")
sentimentr::sentiment("This is an excellent sample sentence")
sentimentr::sentiment("This is not an excellent sample sentence")
